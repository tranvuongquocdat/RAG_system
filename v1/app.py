"""
Main Application for RAG System
á»¨ng dá»¥ng chÃ­nh Ä‘á»ƒ cháº¡y há»‡ thá»‘ng RAG vá»›i CLI vÃ  API
"""

import os
import sys
import asyncio
import argparse
from typing import Optional, Dict, Any, List
from pathlib import Path
import uvicorn
from fastapi import FastAPI, HTTPException, UploadFile, File, Form, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import shutil

# Import cÃ¡c modules cá»§a há»‡ thá»‘ng
from config import get_config, validate_config
from utils import setup_logging, format_file_size, create_directory_if_not_exists
from embedding import create_embedding_manager
from database import create_qdrant_manager
from ingestion import create_ingestion_pipeline
from retrieval import create_retrieval_engine, create_context_builder
from generation import create_rag_chain, create_conversational_rag
from model import create_llm_manager

# Pydantic models cho API
class QueryRequest(BaseModel):
    question: str = Field(..., description="CÃ¢u há»i tá»« ngÆ°á»i dÃ¹ng")
    max_sources: Optional[int] = Field(5, description="Sá»‘ lÆ°á»£ng sources tá»‘i Ä‘a")
    filters: Optional[Dict[str, Any]] = Field(None, description="Bá»™ lá»c cho retrieval")

class QueryResponse(BaseModel):
    answer: str
    confidence_score: float
    sources: List[Dict[str, Any]]
    processing_time: float
    metadata: Dict[str, Any]

class IngestionRequest(BaseModel):
    file_path: str = Field(..., description="ÄÆ°á»ng dáº«n file cáº§n ingest")
    metadata: Optional[Dict[str, Any]] = Field(None, description="Metadata bá»• sung")

class IngestionResponse(BaseModel):
    success: bool
    message: str
    documents_processed: int
    processing_time: float

class ConversationRequest(BaseModel):
    conversation_id: str = Field(..., description="ID cuá»™c há»™i thoáº¡i")
    question: str = Field(..., description="CÃ¢u há»i")
    use_context: Optional[bool] = Field(True, description="Sá»­ dá»¥ng context há»™i thoáº¡i")

class SystemStats(BaseModel):
    total_documents: int
    collection_info: Dict[str, Any]
    embedding_cache_size: int
    system_status: str

class RAGSystem:
    """
    Há»‡ thá»‘ng RAG chÃ­nh
    """
    
    def __init__(self):
        """Khá»Ÿi táº¡o há»‡ thá»‘ng RAG"""
        self.config = get_config()
        self.logger = setup_logging(self.config.app.log_level, self.config.app.log_file)
        
        # Validate configuration
        if not validate_config():
            raise ValueError("Cáº¥u hÃ¬nh khÃ´ng há»£p lá»‡")
        
        self.logger.info("ğŸš€ Äang khá»Ÿi táº¡o RAG System...")
        
        # Initialize components
        self._initialize_components()
        
        self.logger.info("âœ… RAG System Ä‘Ã£ khá»Ÿi táº¡o thÃ nh cÃ´ng")
    
    def _initialize_components(self) -> None:
        """Khá»Ÿi táº¡o cÃ¡c components cá»§a há»‡ thá»‘ng"""
        try:
            # Initialize embedding manager
            self.embedding_manager = create_embedding_manager()
            
            # Initialize Qdrant manager
            self.qdrant_manager = create_qdrant_manager()
            
            # Initialize ingestion pipeline
            self.ingestion_pipeline = create_ingestion_pipeline(
                self.embedding_manager, 
                self.qdrant_manager
            )
            
            # Initialize LLM manager
            self.llm_manager = create_llm_manager()
            
            # Initialize retrieval engine
            self.retrieval_engine = create_retrieval_engine(
                self.embedding_manager,
                self.qdrant_manager
            )
            
            # Initialize context builder
            self.context_builder = create_context_builder(self.retrieval_engine)
            
            # Initialize RAG chain
            self.rag_chain = create_rag_chain(
                self.llm_manager,
                self.retrieval_engine,
                self.context_builder
            )
            
            # Initialize conversational RAG
            self.conversational_rag = create_conversational_rag(self.rag_chain)
            
            self.logger.info("âœ… Táº¥t cáº£ components Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o")
            
        except Exception as e:
            self.logger.error(f"âŒ Lá»—i khá»Ÿi táº¡o components: {str(e)}")
            raise
    
    def query(
        self,
        question: str,
        max_sources: Optional[int] = None,
        filters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Xá»­ lÃ½ cÃ¢u há»i vÃ  tráº£ vá» káº¿t quáº£
        
        Args:
            question: CÃ¢u há»i tá»« ngÆ°á»i dÃ¹ng
            max_sources: Sá»‘ lÆ°á»£ng sources tá»‘i Ä‘a
            filters: Bá»™ lá»c cho retrieval
            
        Returns:
            Dictionary chá»©a káº¿t quáº£
        """
        try:
            result = self.rag_chain.generate_answer(
                question=question,
                max_sources=max_sources,
                filters=filters
            )
            
            # Convert sources to dict format
            sources_dict = []
            for source in result.sources:
                sources_dict.append({
                    'id': source.id,
                    'content': source.content[:200] + "..." if len(source.content) > 200 else source.content,
                    'score': source.score,
                    'filename': source.filename,
                    'document_type': source.document_type,
                    'chunk_id': source.chunk_id,
                    'source': source.source
                })
            
            return {
                'answer': result.answer,
                'confidence_score': result.confidence_score,
                'sources': sources_dict,
                'processing_time': result.processing_time,
                'response_type': result.response_type.value,
                'metadata': result.metadata
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Lá»—i xá»­ lÃ½ query: {str(e)}")
            raise
    
    def ingest_file(
        self,
        file_path: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Ingest má»™t file vÃ o há»‡ thá»‘ng
        
        Args:
            file_path: ÄÆ°á»ng dáº«n file
            metadata: Metadata bá»• sung
            
        Returns:
            Dictionary chá»©a káº¿t quáº£ ingestion
        """
        try:
            import time
            start_time = time.time()
            
            # Process and ingest file
            documents = self.ingestion_pipeline.process_single_file(file_path, metadata)
            
            if documents:
                success = self.ingestion_pipeline.ingest_documents(documents)
                processing_time = time.time() - start_time
                
                return {
                    'success': success,
                    'message': f"ÄÃ£ ingest {len(documents)} documents tá»« file {Path(file_path).name}",
                    'documents_processed': len(documents),
                    'processing_time': processing_time
                }
            else:
                return {
                    'success': False,
                    'message': f"KhÃ´ng thá»ƒ xá»­ lÃ½ file {Path(file_path).name}",
                    'documents_processed': 0,
                    'processing_time': time.time() - start_time
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Lá»—i ingest file: {str(e)}")
            raise
    
    def ingest_directory(
        self,
        directory_path: str,
        recursive: bool = True
    ) -> Dict[str, Any]:
        """
        Ingest toÃ n bá»™ directory
        
        Args:
            directory_path: ÄÆ°á»ng dáº«n thÆ° má»¥c
            recursive: CÃ³ xá»­ lÃ½ Ä‘á»‡ quy khÃ´ng
            
        Returns:
            Dictionary chá»©a káº¿t quáº£ ingestion
        """
        try:
            import time
            start_time = time.time()
            
            success = self.ingestion_pipeline.ingest_directory(directory_path, recursive)
            processing_time = time.time() - start_time
            
            # Get stats after ingestion
            stats = self.ingestion_pipeline.get_ingestion_stats()
            
            return {
                'success': success,
                'message': f"ÄÃ£ ingest directory {directory_path}",
                'total_documents': stats.get('total_documents', 0),
                'processing_time': processing_time
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Lá»—i ingest directory: {str(e)}")
            raise
    
    def get_system_stats(self) -> Dict[str, Any]:
        """
        Láº¥y thá»‘ng kÃª há»‡ thá»‘ng
        
        Returns:
            Dictionary chá»©a thá»‘ng kÃª
        """
        try:
            ingestion_stats = self.ingestion_pipeline.get_ingestion_stats()
            collection_info = self.qdrant_manager.get_collection_info()
            
            return {
                'total_documents': ingestion_stats.get('total_documents', 0),
                'collection_info': collection_info,
                'embedding_cache_size': self.embedding_manager.get_cache_size(),
                'system_status': 'healthy',
                'config': {
                    'model_provider': self.config.get_primary_llm_provider(),
                    'embedding_model': self.config.model.gemini_embedding_model,
                    'vector_dimension': ingestion_stats.get('vector_dimension', 0),
                    'collection_name': self.config.qdrant.collection_name
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Lá»—i láº¥y system stats: {str(e)}")
            return {
                'total_documents': 0,
                'collection_info': {},
                'embedding_cache_size': 0,
                'system_status': 'error',
                'error': str(e)
            }

# Global RAG system instance
rag_system: Optional[RAGSystem] = None

def get_rag_system() -> RAGSystem:
    """Dependency Ä‘á»ƒ láº¥y RAG system instance"""
    global rag_system
    if rag_system is None:
        rag_system = RAGSystem()
    return rag_system

# FastAPI app
app = FastAPI(
    title="Enterprise RAG System",
    description="Há»‡ thá»‘ng RAG cho doanh nghiá»‡p sá»­ dá»¥ng LangChain vÃ  Qdrant",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# API Routes
@app.get("/")
async def root():
    """Root endpoint"""
    return {"message": "Enterprise RAG System API", "status": "running"}

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    try:
        system = get_rag_system()
        stats = system.get_system_stats()
        return {"status": "healthy", "stats": stats}
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}

@app.post("/query", response_model=QueryResponse)
async def query_documents(
    request: QueryRequest,
    system: RAGSystem = Depends(get_rag_system)
):
    """Query documents endpoint"""
    try:
        result = system.query(
            question=request.question,
            max_sources=request.max_sources,
            filters=request.filters
        )
        
        return QueryResponse(**result)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ingest/file", response_model=IngestionResponse)
async def ingest_file_endpoint(
    request: IngestionRequest,
    system: RAGSystem = Depends(get_rag_system)
):
    """Ingest file endpoint"""
    try:
        result = system.ingest_file(
            file_path=request.file_path,
            metadata=request.metadata
        )
        
        return IngestionResponse(**result)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ingest/upload")
async def upload_and_ingest(
    file: UploadFile = File(...),
    metadata: str = Form("{}"),
    system: RAGSystem = Depends(get_rag_system)
):
    """Upload vÃ  ingest file endpoint"""
    try:
        import json
        import tempfile
        
        # Parse metadata
        try:
            metadata_dict = json.loads(metadata) if metadata != "{}" else {}
        except json.JSONDecodeError:
            metadata_dict = {}
        
        # Save uploaded file to temp location
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.filename).suffix) as temp_file:
            shutil.copyfileobj(file.file, temp_file)
            temp_path = temp_file.name
        
        try:
            # Ingest the file
            result = system.ingest_file(temp_path, metadata_dict)
            return result
        finally:
            # Clean up temp file
            os.unlink(temp_path)
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/conversation")
async def conversation_endpoint(
    request: ConversationRequest,
    system: RAGSystem = Depends(get_rag_system)
):
    """Conversational query endpoint"""
    try:
        result = system.conversational_rag.chat(
            conversation_id=request.conversation_id,
            question=request.question,
            use_conversation_context=request.use_context
        )
        
        # Convert to dict format
        sources_dict = []
        for source in result.sources:
            sources_dict.append({
                'id': source.id,
                'content': source.content[:200] + "..." if len(source.content) > 200 else source.content,
                'score': source.score,
                'filename': source.filename,
                'document_type': source.document_type
            })
        
        return {
            'answer': result.answer,
            'confidence_score': result.confidence_score,
            'sources': sources_dict,
            'processing_time': result.processing_time,
            'conversation_id': request.conversation_id
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/stats", response_model=SystemStats)
async def get_stats(system: RAGSystem = Depends(get_rag_system)):
    """Get system statistics"""
    try:
        stats = system.get_system_stats()
        return SystemStats(
            total_documents=stats['total_documents'],
            collection_info=stats['collection_info'],
            embedding_cache_size=stats['embedding_cache_size'],
            system_status=stats['system_status']
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/documents/{document_id}")
async def delete_document(
    document_id: str,
    system: RAGSystem = Depends(get_rag_system)
):
    """Delete a document"""
    try:
        success = system.qdrant_manager.delete_documents([document_id])
        return {"success": success, "message": f"Document {document_id} deleted"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# CLI Functions
def run_cli():
    """Cháº¡y CLI interface"""
    config = get_config()
    logger = setup_logging(config.app.log_level, config.app.log_file)
    
    print("ğŸš€ Enterprise RAG System CLI")
    print("=" * 50)
    
    try:
        # Initialize system
        system = RAGSystem()
        
        while True:
            print("\nCÃ¡c lá»‡nh cÃ³ sáºµn:")
            print("1. query - Äáº·t cÃ¢u há»i")
            print("2. ingest - Ingest file/directory")
            print("3. stats - Xem thá»‘ng kÃª há»‡ thá»‘ng")
            print("4. exit - ThoÃ¡t")
            
            choice = input("\nChá»n lá»‡nh (1-4): ").strip()
            
            if choice == "1":
                question = input("Nháº­p cÃ¢u há»i: ").strip()
                if question:
                    print("\nğŸ” Äang xá»­ lÃ½...")
                    result = system.query(question)
                    
                    print(f"\nâœ… CÃ¢u tráº£ lá»i (Confidence: {result['confidence_score']:.2f}):")
                    print("-" * 50)
                    print(result['answer'])
                    print(f"\nğŸ“š Sources: {len(result['sources'])} documents")
                    print(f"â±ï¸ Processing time: {result['processing_time']:.2f}s")
            
            elif choice == "2":
                path = input("Nháº­p Ä‘Æ°á»ng dáº«n file/directory: ").strip()
                if path and os.path.exists(path):
                    print("\nğŸ“¥ Äang ingest...")
                    
                    if os.path.isfile(path):
                        result = system.ingest_file(path)
                    else:
                        result = system.ingest_directory(path)
                    
                    if result['success']:
                        print(f"âœ… {result['message']}")
                        print(f"ğŸ“„ Documents: {result.get('documents_processed', result.get('total_documents', 0))}")
                        print(f"â±ï¸ Time: {result['processing_time']:.2f}s")
                    else:
                        print(f"âŒ {result['message']}")
                else:
                    print("âŒ ÄÆ°á»ng dáº«n khÃ´ng tá»“n táº¡i")
            
            elif choice == "3":
                print("\nğŸ“Š Thá»‘ng kÃª há»‡ thá»‘ng:")
                print("-" * 30)
                stats = system.get_system_stats()
                print(f"ğŸ“„ Total documents: {stats['total_documents']}")
                print(f"ğŸ§  Embedding cache: {stats['embedding_cache_size']}")
                print(f"ğŸ”§ Status: {stats['system_status']}")
                print(f"ğŸ¤– Model: {stats['config']['model_provider']}")
                print(f"ğŸ”¢ Vector dimension: {stats['config']['vector_dimension']}")
            
            elif choice == "4":
                print("ğŸ‘‹ Táº¡m biá»‡t!")
                break
            
            else:
                print("âŒ Lá»±a chá»n khÃ´ng há»£p lá»‡")
                
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Táº¡m biá»‡t!")
    except Exception as e:
        logger.error(f"âŒ Lá»—i CLI: {str(e)}")
        print(f"âŒ Lá»—i: {str(e)}")

def run_api():
    """Cháº¡y API server"""
    config = get_config()
    
    print("ğŸš€ Starting Enterprise RAG System API...")
    print(f"ğŸ“¡ Host: {config.app.api_host}:{config.app.api_port}")
    print("ğŸ“– Docs: http://localhost:8000/docs")
    
    uvicorn.run(
        "app:app",
        host=config.app.api_host,
        port=config.app.api_port,
        reload=False,
        log_level=config.app.log_level.lower()
    )

def main():
    """Main function"""
    parser = argparse.ArgumentParser(description="Enterprise RAG System")
    parser.add_argument(
        "mode",
        choices=["cli", "api"],
        help="Cháº¿ Ä‘á»™ cháº¡y: cli hoáº·c api"
    )
    parser.add_argument(
        "--config-check",
        action="store_true",
        help="Kiá»ƒm tra cáº¥u hÃ¬nh"
    )
    
    args = parser.parse_args()
    
    # Check configuration
    if args.config_check:
        print("ğŸ”§ Kiá»ƒm tra cáº¥u hÃ¬nh...")
        if validate_config():
            print("âœ… Cáº¥u hÃ¬nh há»£p lá»‡")
        else:
            print("âŒ Cáº¥u hÃ¬nh khÃ´ng há»£p lá»‡")
            sys.exit(1)
        return
    
    # Run in selected mode
    try:
        if args.mode == "cli":
            run_cli()
        elif args.mode == "api":
            run_api()
    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi Ä‘á»™ng: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()



Project:  Pricing  Optimization  
Documentation  
Security  This  document  may  not  be  shared  in  any  form  outside  the  scope  of  the  project's  
development.
 
Project  
●  Objective:  To  obtain  more  favorable  prices  on  files  that  have  not  yet  been  issued.  ●  Statement:  The  organization  wants  to  improve  its  pricing  optimization  system,  which  is  
currently
 
based
 
on
 
automatic
 
rebookings
 
and
 
specific
 
alerts.
 
The
 
current
 
approach
 
is
 
limited
 
because
 
it
 
analyzes
 
files
 
one
 
by
 
one,
 
lacks
 
a
 
global
 
view,
 
and
 
doesn't
 
use
 
historical
 
or
 
competitive
 
data,
 
so
 
a
 
more
 
structured
 
process
 
is
 
needed.
 ●  Goal:  The  project  aims  to  consolidate  data  from  logs  and  bookings,  identify  the  best  time  
windows
 
for
 
optimization,
 
and
 
create
 
an
 
operational
 
report
 
that
 
can
 
be
 
used
 
by
 
the
 
teams.
 
Context  Currently,  the  pricing  optimization  system  detects  price  drop  opportunities  as  they  
happen,
 
without
 
prioritizing
 
or
 
grouping
 
them
 
across
 
multiple
 
files.
 
This
 
leads
 
to
 
a
 
waste
 
of
 
time
 
and
 
underutilizes
 
the
 
potential
 
for
 
savings.
 
The
 
project's
 
goal
 
is
 
to
 
develop
 
an
 
automated
 
workflow
 
that
 
can:
 
●  Join  and  structure  raw  data  (logs,  bookings).  ●  Isolate  relevant  optimizations  (status  S).  ●  Analyze  gains  and  itineraries.  ●  Identify  the  best  opportunities  by  day  and  route  through  aggregation.  ●  Return  these  results  in  a  usable  format  and  distribute  them  automatically.  
 
Specifications  
1.  Development  Environment  To  simplify  development,  the  client  has  provided  database  
extracts
 
in
 
.csv
 
format.
 
Once
 
the
 
optimization
 
script
 
is
 
ready,
 
the
 
team
 
will
 
need
 
to
 
connect
 
to
 
an
 
API
 
to
 
get
 
the
 
data
 
instead
 
of
 
using
 
these
 
.csv
 
files.
 
The
 
API
 
will
 
provide
 
the
 
data
 
in
 
an
 
identical
 
format.
 
The
 
data
 
volume
 
is
 
about
 
1GB
 
once
 
connected
 
to
 
the
 
API.
 
2.  Data  Joining  
●  Files:  cdv_log_operation.csv (logs)  and  cdv_wnj_air_booking_view.csv 
(bookings).
 ●  Join  Key:  cdv_log_operation.lgop_element_id =  cdv_wnj_air_booking_view.wbkg_reference.  
●  Action:  Join  the  two  tables  to  extract  the  necessary  data  for  calculating  the  optimization  
datetimes.
 
3.  Record  Filtering  
●  Action:  Keep  only  the  rows  where  cdv_log_operation.lgop_status =  'S'.  
4.  Data  Extraction  for  Calculations  
●  Optimization  Datetime:  cdv_log_operation.lgop_when.  ●  Airline:  cdv_wnj_air_booking_view.dair_code.  ●  Start  of  Trip:  cdv_wnj_air_booking_view.FromAirportCode.  ●  End  of  Trip:  cdv_wnj_air_booking_view.ToAirportCode.  ●  Travel  Dates:  cdv_wnj_air_booking_view.wbkg_start_date.  ●  Gain:  From  cdv_log_operation.lgop_results.  
 
5.  Analytical  Aggregation  of  the  Optimization  List  
●  Sort  records  by  airline:   cdv_wnj_air_booking_view.dair_code.  ●  For  each  airline  (cdv_wnj_air_booking_view.dair_code),  keep  the  records  with  
the
 
best
 
gains
 
(cdv_log_operation.lgop_results)  when  the  Start  of  trip,  End  of  
trip,
 
and
 
Travel
 
dates
 
are
 
identical.
 ●  For  each  airline,  if  one  of  the  conditions  (Start  of  trip,  End  of  trip,  or  Travel  dates)  is  not  
identical,
 
keep
 
the
 
row.
 ●  Generate  the  CSV  file  named  
 listeOptimisation_dd-MM-yyyy.csv,  where  dd-MM-yyyy is  the  date  the  file  is  
generated.
 ●  Refer  to  the  example  Excel  file  (Exemple  rapport  optimisation.xlsx)  and  fill  in  
all
 
the
 
required
 
data
 
based
 
on
 
its
 
correspondence.
 
6.  Nuanced  Time  Analysis  
●  For  each  airline,  after  extracting  the  best  gains,  the  goal  is  to  find  average  trends.  ●  Calculate  the  average  gains  by:  ○  Time  of  day  (e.g.,  gains  are,  on  average,  better  around  3  a.m.).  ○  Day  of  the  week  (e.g.,  Tuesday  is  more  favorable  than  Friday).  ○  Combined  day  +  hour  (e.g.,  Monday  at  10  a.m.  gives  the  best  average  results).  ●  From  the  
 cdv_log_operation.lgop_when column  (optimization  datetime),  extract  the  hour  of  
the
 
day
 
(an
 
integer
 
from
 
0
 
to
 
23)
 
and
 
the
 
day
 
of
 
the
 
week.
 ●  Average  by  Time  of  Day:  Group  all  rows  by  hour  (regardless  of  the  day)  and  calculate  
the
 
average
 
gain
 
for
 
each
 
hour.
 
●  Average  by  Day  of  the  Week:  Group  all  rows  by  the  day  of  the  week  and  calculate  the  
average
 
gain
 
for
 
each
 
day.
 ●  Combined  Average  (Day  +  Hour):  Create  a  combination  of  day  +  hour  (e.g.,  Monday  at  
10
 
a.m.,
 
Monday
 
at
 
11
 
a.m.,
 
Tuesday
 
at
 
9
 
a.m.,
 
etc.,
 
which
 
is
 
7×24
 
combinations).
 
Calculate
 
the
 
average
 
gain
 
for
 
each
 
combination.
 ●  Ranking  Slots:  For  each  grouping  (hour  only,  day  only,  day  +  hour),  sort  the  results  by  
average
 
gain
 
in
 
descending
 
order.
 
Keep
 
the
 
 
TOP
 
3
 
for
 
each
 
grouping.
 ●  JSON  Output:  Save  the  results  in  a  file  named  topOptimisation.json.  The  file  
format
 
is
 
specified
 
in
 
the
 
document
 
.
 
7.  Results  Distribution  
●  Deposit  the  CSV  and  JSON  files  on  an  SFTP  space  (coordinates  to  be  specified).  ●  The  files  must  be  deposited  between  2  a.m.  and  4  a.m.  GMT+1.  
Data  Provision  
To  facilitate  development,  the  client  is  providing  two  databases  in  .CSV  format,  which  represent  
20-30%
 
of
 
the
 
total
 
data
 
volume
 
to
 
be
 
processed:
 
●  cdv_log_operation.csv  ●  cdv_wnj_air_booking_view.csv  
Their  architecture  files  are  also  provided:  
●  cdv_log_operation.md  ●  cdv_wnj_air_booking_view.md  
The  Excel  file  for  building  the  CSV  report  is  also  included  (Exemple  rapport  
optimisation.xlsx).  The  data  order  must  be  respected  as  transmitted  in  the  file.  
Additional  Information  
●  The  required  technology  for  this  project  is  Python .  
 
Development  Timeline  (Adjusted)  
●  Phase  0  -  Project  Launch:  September  3-5,  2025  ○  Retrieve  and  validate  example  files  (CSV  extracts).  ○  Set  up  the  local  development  environment.  ○  Verify  data  schemas  and  formats.  ●  Phase  1  -  Development:  September  8-26,  2025  
○  Develop  the  application.  ●  Phase  2  -  API  Connection  and  Project  Follow-up:  ○  September  15,  2025:  API  for  real  data  retrieval  becomes  available.  ○  September  16,  2025:  Project  meeting  with  the  client  to  validate  the  API  
connection
 
and
 
progress.
 ●  Phase  3  -  Advanced  Feature  Development:  September  17-19,  2025  ○  Adapt  the  pipeline  for  ingestion  via  the  API  (instead  of  CSVs).  ○  Verify  schema  compatibility  between  CSV  and  API.  ●  Phase  4  -  Finalization:  September  29  -  October  2,  2025  ○  Run  unit  and  performance  tests  on  ~1  GB  of  data.  ○  Make  adjustments  based  on  client  feedback.  ●  Phase  5  -  Delivery  and  Final  Acceptance:  October  3,  2025  ○  Put  the  application  into  production  on  the  client's  environment  (server  
configuration
 
handled
 
by
 
the
 
client).
 ○  Final  acceptance.  
Key  Milestones:  
●  September  3:  Start  of  development  with  example  files.  ●  September  15:  API  becomes  available.  ●  September  16:  Follow-up  meeting.  ●  October  3:  Production  delivery.  
         
